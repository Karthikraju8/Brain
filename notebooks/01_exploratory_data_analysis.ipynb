{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Detection - Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the MRI brain tumor dataset to understand:\n",
    "- Data distribution\n",
    "- Image characteristics\n",
    "- Class balance\n",
    "- Sample visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "from config import RAW_DATA_DIR, CLASS_NAMES, IMAGE_SIZE\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(f\"Data directory: {RAW_DATA_DIR}\")\n",
    "print(f\"Classes: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per class\n",
    "class_counts = {}\n",
    "\n",
    "for class_name in CLASS_NAMES:\n",
    "    class_dir = RAW_DATA_DIR / class_name\n",
    "    if class_dir.exists():\n",
    "        images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + list(class_dir.glob('*.png'))\n",
    "        class_counts[class_name] = len(images)\n",
    "    else:\n",
    "        class_counts[class_name] = 0\n",
    "        print(f\"⚠️ Directory not found: {class_dir}\")\n",
    "\n",
    "# Display counts\n",
    "total = sum(class_counts.values())\n",
    "print(f\"\\nTotal images: {total}\")\n",
    "print(\"\\nImages per class:\")\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"  {cls}: {count} ({count/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = sns.color_palette('husl', len(class_counts))\n",
    "bars = ax.bar(class_counts.keys(), class_counts.values(), color=colors)\n",
    "\n",
    "# Add count labels\n",
    "for bar, count in zip(bars, class_counts.values()):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20,\n",
    "            str(count), ha='center', fontsize=12)\n",
    "\n",
    "ax.set_xlabel('Tumor Type', fontsize=12)\n",
    "ax.set_ylabel('Number of Images', fontsize=12)\n",
    "ax.set_title('Brain Tumor Dataset - Class Distribution', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from each class\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "\n",
    "for row, class_name in enumerate(CLASS_NAMES):\n",
    "    class_dir = RAW_DATA_DIR / class_name\n",
    "    if class_dir.exists():\n",
    "        images = list(class_dir.glob('*.jpg'))[:5]\n",
    "        for col, img_path in enumerate(images):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            axes[row, col].imshow(img)\n",
    "            axes[row, col].axis('off')\n",
    "            if col == 0:\n",
    "                axes[row, col].set_ylabel(class_name, fontsize=12)\n",
    "\n",
    "plt.suptitle('Sample MRI Images by Tumor Type', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Properties Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image sizes and properties\n",
    "image_sizes = []\n",
    "image_channels = []\n",
    "\n",
    "for class_name in CLASS_NAMES:\n",
    "    class_dir = RAW_DATA_DIR / class_name\n",
    "    if class_dir.exists():\n",
    "        images = list(class_dir.glob('*.jpg'))[:50]  # Sample 50 images\n",
    "        for img_path in images:\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is not None:\n",
    "                h, w = img.shape[:2]\n",
    "                c = img.shape[2] if len(img.shape) > 2 else 1\n",
    "                image_sizes.append((w, h))\n",
    "                image_channels.append(c)\n",
    "\n",
    "# Statistics\n",
    "sizes_array = np.array(image_sizes)\n",
    "print(\"Image Size Statistics:\")\n",
    "print(f\"  Width  - Min: {sizes_array[:,0].min()}, Max: {sizes_array[:,0].max()}, Mean: {sizes_array[:,0].mean():.0f}\")\n",
    "print(f\"  Height - Min: {sizes_array[:,1].min()}, Max: {sizes_array[:,1].max()}, Mean: {sizes_array[:,1].mean():.0f}\")\n",
    "print(f\"\\nChannel distribution: {Counter(image_channels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot size distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].hist(sizes_array[:,0], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Width (pixels)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Image Width Distribution')\n",
    "\n",
    "axes[1].hist(sizes_array[:,1], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Height (pixels)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Image Height Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pixel Intensity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pixel intensity distributions per class\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, class_name in enumerate(CLASS_NAMES):\n",
    "    class_dir = RAW_DATA_DIR / class_name\n",
    "    if class_dir.exists():\n",
    "        all_pixels = []\n",
    "        images = list(class_dir.glob('*.jpg'))[:20]\n",
    "        for img_path in images:\n",
    "            img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                all_pixels.extend(img.flatten())\n",
    "        \n",
    "        axes[idx].hist(all_pixels, bins=50, edgecolor='black', alpha=0.7, density=True)\n",
    "        axes[idx].set_xlabel('Pixel Intensity')\n",
    "        axes[idx].set_ylabel('Density')\n",
    "        axes[idx].set_title(f'{class_name.title()} - Pixel Distribution')\n",
    "\n",
    "plt.suptitle('Pixel Intensity Distribution by Tumor Type', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocessing import MRISpecificPreprocessor\n",
    "\n",
    "preprocessor = MRISpecificPreprocessor()\n",
    "\n",
    "# Get a sample image\n",
    "sample_path = list((RAW_DATA_DIR / 'glioma').glob('*.jpg'))[0]\n",
    "original = cv2.imread(str(sample_path))\n",
    "original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Apply preprocessing steps\n",
    "resized = cv2.resize(original, IMAGE_SIZE)\n",
    "gray = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY)\n",
    "denoised = preprocessor.apply_denoising(gray)\n",
    "clahe = preprocessor.apply_clahe(denoised)\n",
    "normalized = preprocessor.normalize(clahe)\n",
    "\n",
    "# Display preprocessing steps\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "axes[0].imshow(original)\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(resized)\n",
    "axes[1].set_title(f'Resized ({IMAGE_SIZE})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(denoised, cmap='gray')\n",
    "axes[2].set_title('Denoised')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(clahe, cmap='gray')\n",
    "axes[3].set_title('CLAHE Enhanced')\n",
    "axes[3].axis('off')\n",
    "\n",
    "axes[4].imshow(normalized, cmap='gray')\n",
    "axes[4].set_title('Normalized')\n",
    "axes[4].axis('off')\n",
    "\n",
    "plt.suptitle('Preprocessing Pipeline', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "### Key Findings:\n",
    "- Dataset contains MRI brain scans categorized into 4 classes\n",
    "- Image sizes vary - will need resizing for model input\n",
    "- Class distribution may require attention (check for imbalance)\n",
    "- Preprocessing steps help enhance image quality\n",
    "\n",
    "### Next Steps:\n",
    "1. Preprocess all images using the pipeline\n",
    "2. Apply data augmentation to balance classes\n",
    "3. Train the X-Farmer model\n",
    "4. Evaluate on test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
